{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî• XPLIA TIER 1 - Advanced Features\n",
    "\n",
    "Explore cutting-edge XAI features that NO other library has!\n",
    "\n",
    "## TIER 1 Modules:\n",
    "1. üé® Multimodal AI (CLIP, Stable Diffusion)\n",
    "2. üï∏Ô∏è Graph Neural Networks\n",
    "3. üéÆ Reinforcement Learning\n",
    "4. üîÑ Advanced Counterfactuals\n",
    "5. üìà Time Series\n",
    "6. üé≠ Generative Models (VAE, GAN, StyleGAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. üé® Multimodal AI - Vision-Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xplia.explainers.multimodal import CLIPExplainer, StableDiffusionExplainer\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Create CLIP explainer\n",
    "clip_explainer = CLIPExplainer()\n",
    "\n",
    "# Load an image (or create dummy for demo)\n",
    "image = np.random.rand(224, 224, 3).astype(np.float32)\n",
    "text = \"a photo of a cat on a table\"\n",
    "\n",
    "# Explain vision-language model\n",
    "explanation = clip_explainer.explain(image, text, method='attention')\n",
    "\n",
    "print(f\"Similarity Score: {explanation.similarity_score:.3f}\")\n",
    "print(f\"Important Text Tokens: {explanation.important_text_tokens}\")\n",
    "print(f\"Important Image Regions: {explanation.important_regions[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable Diffusion Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain Stable Diffusion generation\n",
    "diffusion_explainer = StableDiffusionExplainer()\n",
    "\n",
    "prompt = \"a beautiful sunset over mountains, highly detailed\"\n",
    "generated_image = np.random.rand(512, 512, 3).astype(np.float32)\n",
    "\n",
    "explanation = diffusion_explainer.explain(prompt, generated_image)\n",
    "\n",
    "print(\"Prompt Token Importance:\")\n",
    "for token, importance in explanation.prompt_token_importance.items():\n",
    "    print(f\"  {token}: {importance:.3f}\")\n",
    "\n",
    "print(f\"\\nMost Important Timesteps: {explanation.timestep_importance[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. üï∏Ô∏è Graph Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xplia.explainers.graph import GNNExplainer, MolecularGNNExplainer\n",
    "\n",
    "# Create dummy graph\n",
    "graph = {\n",
    "    'node_features': np.random.rand(10, 5),\n",
    "    'edge_index': np.random.randint(0, 10, (2, 15)),\n",
    "    'num_nodes': 10,\n",
    "    'num_edges': 15\n",
    "}\n",
    "\n",
    "# Explain GNN prediction\n",
    "gnn_explainer = GNNExplainer()\n",
    "explanation = gnn_explainer.explain_node(graph, node_idx=0)\n",
    "\n",
    "print(f\"Important Nodes: {explanation.important_nodes}\")\n",
    "print(f\"Important Edges: {explanation.important_edges}\")\n",
    "print(f\"Node Importance:\\n{explanation.node_importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Molecular Explainability for Drug Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain molecular properties\n",
    "mol_explainer = MolecularGNNExplainer()\n",
    "\n",
    "molecule = {\n",
    "    'atom_features': np.random.rand(20, 10),\n",
    "    'bond_index': np.random.randint(0, 20, (2, 25)),\n",
    "    'bond_features': np.random.rand(25, 4),\n",
    "    'num_atoms': 20,\n",
    "    'num_bonds': 25,\n",
    "    'smiles': 'CCO'\n",
    "}\n",
    "\n",
    "# Explain toxicity\n",
    "tox_explanation = mol_explainer.explain_toxicity(molecule)\n",
    "\n",
    "print(\"Toxicophores (structural alerts):\")\n",
    "for alert in tox_explanation.structural_alerts:\n",
    "    print(f\"  - {alert}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. üéÆ Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xplia.explainers.reinforcement import PolicyExplainer, TrajectoryExplainer\n",
    "\n",
    "# Define a simple policy\n",
    "def policy(state):\n",
    "    return {\n",
    "        'action': np.random.randint(0, 2),\n",
    "        'action_probs': np.random.dirichlet([1, 1]),\n",
    "        'value': np.random.rand()\n",
    "    }\n",
    "\n",
    "# Explain policy decisions\n",
    "policy_explainer = PolicyExplainer(policy)\n",
    "\n",
    "state = np.random.rand(4)\n",
    "explanation = policy_explainer.explain_action(state)\n",
    "\n",
    "print(f\"Chosen Action: {explanation.action}\")\n",
    "print(f\"Action Probability: {explanation.action_probability:.2%}\")\n",
    "print(f\"State Feature Importance:\\n{explanation.state_feature_importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectory Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain RL trajectory\n",
    "traj_explainer = TrajectoryExplainer()\n",
    "\n",
    "trajectory = {\n",
    "    'states': [np.random.rand(4) for _ in range(10)],\n",
    "    'actions': [np.random.randint(0, 2) for _ in range(10)],\n",
    "    'rewards': [np.random.rand() for _ in range(10)],\n",
    "    'dones': [False] * 9 + [True]\n",
    "}\n",
    "\n",
    "explanation = traj_explainer.explain_trajectory(trajectory)\n",
    "\n",
    "print(f\"Critical States: {explanation.critical_states}\")\n",
    "print(f\"Critical Actions: {explanation.critical_actions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. üìà Time Series Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xplia.explainers.timeseries import TemporalImportanceExplainer, AnomalyExplainer\n",
    "import pandas as pd\n",
    "\n",
    "# Create time series\n",
    "dates = pd.date_range('2020-01-01', periods=100, freq='D')\n",
    "ts = pd.DataFrame({\n",
    "    'value': np.random.rand(100),\n",
    "    'feature1': np.random.rand(100)\n",
    "}, index=dates)\n",
    "\n",
    "# Explain temporal importance\n",
    "temporal_explainer = TemporalImportanceExplainer(window_size=30)\n",
    "explanation = temporal_explainer.explain(ts)\n",
    "\n",
    "print(f\"Lag Importance: {explanation.lag_importance}\")\n",
    "print(f\"Feature Importance: {explanation.feature_importance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Detection with Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series with anomalies\n",
    "values = np.random.rand(100)\n",
    "values[50] = 10.0  # Inject anomaly\n",
    "ts_anom = pd.Series(values, index=dates)\n",
    "\n",
    "# Detect and explain anomalies\n",
    "anomaly_explainer = AnomalyExplainer(threshold=2.5)\n",
    "explanation = anomaly_explainer.detect_and_explain(ts_anom)\n",
    "\n",
    "print(f\"Anomalies Detected: {len(explanation.anomaly_indices)}\")\n",
    "print(f\"Anomaly Indices: {explanation.anomaly_indices}\")\n",
    "print(f\"Anomaly Reasons: {explanation.anomaly_reasons[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. üé≠ Generative Models - VAE & GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xplia.explainers.generative import VAEExplainer, StyleGANExplainer\n",
    "\n",
    "# Explain VAE latent space\n",
    "vae_explainer = VAEExplainer(latent_dim=8)\n",
    "\n",
    "latent = np.random.randn(8)\n",
    "explanation = vae_explainer.explain_latent_space(latent)\n",
    "\n",
    "print(\"Latent Dimension Importance:\")\n",
    "for dim, importance in explanation.latent_dimensions_importance.items():\n",
    "    print(f\"  Dimension {dim}: {importance:.3f}\")\n",
    "\n",
    "print(f\"\\nDisentanglement Score: {explanation.disentanglement_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StyleGAN W-Space Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain StyleGAN W-space\n",
    "stylegan_explainer = StyleGANExplainer(w_dim=512)\n",
    "\n",
    "w_vector = np.random.randn(512)\n",
    "generated = np.random.rand(1024, 1024, 3)\n",
    "\n",
    "explanation = stylegan_explainer.explain_w_space(w_vector, generated)\n",
    "\n",
    "print(\"Style Factors:\")\n",
    "for factor, value in list(explanation.style_factors.items())[:5]:\n",
    "    print(f\"  {factor}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Key Takeaways\n",
    "\n",
    "TIER 1 features make XPLIA the ONLY library with:\n",
    "\n",
    "- ‚úÖ Multimodal AI explainability (CLIP, Stable Diffusion)\n",
    "- ‚úÖ GNN and molecular explainability\n",
    "- ‚úÖ RL policy and trajectory explanations\n",
    "- ‚úÖ Advanced time series explanations\n",
    "- ‚úÖ Generative model latent space analysis\n",
    "\n",
    "**Next:** Check out TIER 2 & 3 features in the advanced notebooks!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
