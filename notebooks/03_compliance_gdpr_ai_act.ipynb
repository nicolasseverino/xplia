{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèõÔ∏è XPLIA Compliance - GDPR & EU AI Act\n",
    "\n",
    "**XPLIA is the ONLY XAI library with built-in regulatory compliance!**\n",
    "\n",
    "## What You'll Learn:\n",
    "1. GDPR Compliance (Right to Explanation, DPIA)\n",
    "2. EU AI Act Risk Assessment\n",
    "3. HIPAA Compliance for Healthcare\n",
    "4. Audit Trails and Documentation\n",
    "5. Fairwashing Detection (UNIQUE to XPLIA!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xplia import create_explainer\n",
    "from xplia.compliance import GDPRCompliance, AIActCompliance, HIPAACompliance\n",
    "from xplia.explainers.trust import FairwashingDetector, UncertaintyQuantifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Train a Credit Scoring Model\n",
    "\n",
    "This is a HIGH RISK use case under EU AI Act!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic credit scoring data\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_informative=8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "feature_names = [\n",
    "    'income', 'debt_ratio', 'credit_history', 'employment_years',\n",
    "    'age', 'num_dependents', 'assets', 'liabilities',\n",
    "    'loan_amount', 'loan_purpose'\n",
    "]\n",
    "\n",
    "X_df = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_df, y)\n",
    "\n",
    "print(f\"Model trained with accuracy: {model.score(X_df, y):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GDPR Compliance\n",
    "\n",
    "### Article 13-15: Right to Explanation\n",
    "### Article 35: DPIA (Data Protection Impact Assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GDPR compliance checker\n",
    "gdpr = GDPRCompliance(model, model_metadata={\n",
    "    'name': 'Credit Scoring Model v1.0',\n",
    "    'purpose': 'Automated loan approval decision',\n",
    "    'legal_basis': 'legitimate_interest',\n",
    "    'data_retention': '7 years',\n",
    "    'data_processor': 'ACME Bank',\n",
    "    'dpo_contact': 'dpo@acmebank.com'\n",
    "})\n",
    "\n",
    "print(\"‚úÖ GDPR Compliance Checker Created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate DPIA Report (Required by GDPR Article 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data Protection Impact Assessment\n",
    "dpia_report = gdpr.generate_dpia()\n",
    "\n",
    "print(\"DPIA Report Summary:\")\n",
    "print(f\"  - Risk Level: {dpia_report.risk_level}\")\n",
    "print(f\"  - Data Categories: {dpia_report.data_categories}\")\n",
    "print(f\"  - Processing Activities: {len(dpia_report.processing_activities)}\")\n",
    "print(f\"  - Safeguards: {len(dpia_report.safeguards)}\")\n",
    "\n",
    "# Export to PDF for auditors\n",
    "dpia_report.export('gdpr_dpia_report.pdf')\n",
    "print(\"\\n‚úÖ DPIA Report exported to: gdpr_dpia_report.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide Explanation to User (Right to Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create explainer\n",
    "explainer = create_explainer(model, method='shap', background_data=X_df.sample(100))\n",
    "\n",
    "# Explain a rejection decision\n",
    "rejected_applicant = X_df.iloc[0:1]\n",
    "explanation = explainer.explain(rejected_applicant)\n",
    "\n",
    "# Generate GDPR-compliant explanation for user\n",
    "user_explanation = gdpr.generate_user_explanation(\n",
    "    explanation,\n",
    "    decision='REJECTED',\n",
    "    audience='basic'  # Non-technical language\n",
    ")\n",
    "\n",
    "print(\"GDPR-Compliant Explanation for User:\")\n",
    "print(user_explanation.summary)\n",
    "print(\"\\nKey Factors:\")\n",
    "for factor in user_explanation.key_factors:\n",
    "    print(f\"  - {factor}\")\n",
    "print(\"\\nYour Rights:\")\n",
    "for right in user_explanation.user_rights:\n",
    "    print(f\"  - {right}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EU AI Act Compliance\n",
    "\n",
    "### Risk Category Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AI Act compliance checker\n",
    "ai_act = AIActCompliance(model, usage_intent='credit_scoring')\n",
    "\n",
    "# Assess risk category\n",
    "risk_category = ai_act.assess_risk_category()\n",
    "\n",
    "print(f\"EU AI Act Risk Category: {risk_category}\")\n",
    "print(\"\\n‚ö†Ô∏è  Credit scoring is classified as HIGH RISK under EU AI Act!\")\n",
    "print(\"\\nCompliance Requirements:\")\n",
    "for req in ai_act.get_requirements(risk_category):\n",
    "    print(f\"  - {req}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Compliance Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive compliance report\n",
    "compliance_report = ai_act.generate_compliance_report()\n",
    "\n",
    "print(\"EU AI Act Compliance Report:\")\n",
    "print(f\"  - Risk Category: {compliance_report.risk_category}\")\n",
    "print(f\"  - Compliance Status: {compliance_report.compliance_status}\")\n",
    "print(f\"  - Requirements Met: {compliance_report.requirements_met}/{compliance_report.total_requirements}\")\n",
    "print(f\"  - Outstanding Issues: {len(compliance_report.outstanding_issues)}\")\n",
    "\n",
    "# Export report\n",
    "compliance_report.export('eu_ai_act_report.pdf')\n",
    "print(\"\\n‚úÖ AI Act Compliance Report exported to: eu_ai_act_report.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fairwashing Detection (UNIQUE TO XPLIA!)\n",
    "\n",
    "Detect if explanations are hiding biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fairwashing detector\n",
    "detector = FairwashingDetector(model, explainer)\n",
    "\n",
    "# Detect fairwashing\n",
    "X_test = X_df.sample(100)\n",
    "y_test = model.predict(X_test)\n",
    "\n",
    "result = detector.detect(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    sensitive_features=['age', 'gender']  # Example\n",
    ")\n",
    "\n",
    "print(f\"Fairwashing Detected: {result.detected}\")\n",
    "\n",
    "if result.detected:\n",
    "    print(f\"\\n‚ö†Ô∏è  ALERT: Fairwashing Detected!\")\n",
    "    print(f\"Types: {result.fairwashing_types}\")\n",
    "    print(f\"Severity: {result.severity}\")\n",
    "    print(f\"\\nRecommendations:\")\n",
    "    for rec in result.recommendations:\n",
    "        print(f\"  - {rec}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No fairwashing detected - explanations are trustworthy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Uncertainty Quantification (Required for High-Risk AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantify uncertainty (important for compliance)\n",
    "uq = UncertaintyQuantifier(model, explainer)\n",
    "\n",
    "uncertainty = uq.quantify(X_test)\n",
    "\n",
    "print(f\"Average Total Uncertainty: {uncertainty.total_uncertainty.mean():.3f}\")\n",
    "print(f\"Average Epistemic Uncertainty: {uncertainty.epistemic_uncertainty.mean():.3f}\")\n",
    "print(f\"Average Aleatoric Uncertainty: {uncertainty.aleatoric_uncertainty.mean():.3f}\")\n",
    "\n",
    "# Identify high-uncertainty predictions\n",
    "high_uncertainty_mask = uncertainty.total_uncertainty > 0.3\n",
    "high_uncertainty_count = high_uncertainty_mask.sum()\n",
    "\n",
    "print(f\"\\nHigh Uncertainty Predictions: {high_uncertainty_count} ({high_uncertainty_count/len(X_test)*100:.1f}%)\")\n",
    "print(\"\\n‚ö†Ô∏è  Recommendation: Flag high-uncertainty cases for manual review\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. HIPAA Compliance (for Healthcare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For healthcare models\n",
    "hipaa = HIPAACompliance(model)\n",
    "\n",
    "# Log access (required by HIPAA)\n",
    "audit_trail = hipaa.log_access(\n",
    "    user_id='dr_smith_123',\n",
    "    patient_id='patient_456',\n",
    "    purpose='diagnostic_support',\n",
    "    explanation=explanation\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Access logged to HIPAA audit trail\")\n",
    "print(f\"Audit ID: {audit_trail.id}\")\n",
    "print(f\"Timestamp: {audit_trail.timestamp}\")\n",
    "print(f\"User: {audit_trail.user_id}\")\n",
    "print(f\"Patient: {audit_trail.patient_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Comprehensive Compliance Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xplia.visualizations import ChartGenerator\n",
    "\n",
    "# Create compliance dashboard\n",
    "chart_gen = ChartGenerator()\n",
    "\n",
    "chart_gen.create_compliance_dashboard(\n",
    "    gdpr_report=dpia_report,\n",
    "    ai_act_report=compliance_report,\n",
    "    fairwashing_result=result,\n",
    "    uncertainty=uncertainty,\n",
    "    output='compliance_dashboard.html'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Comprehensive Compliance Dashboard created: compliance_dashboard.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Key Takeaways\n",
    "\n",
    "XPLIA is the ONLY XAI library with:\n",
    "\n",
    "- ‚úÖ **GDPR Compliance** - DPIA generation, Right to Explanation\n",
    "- ‚úÖ **EU AI Act Compliance** - Risk assessment, Documentation\n",
    "- ‚úÖ **HIPAA Compliance** - Audit trails for healthcare\n",
    "- ‚úÖ **Fairwashing Detection** - UNIQUE feature!\n",
    "- ‚úÖ **Uncertainty Quantification** - For high-risk AI\n",
    "- ‚úÖ **Automated Reports** - PDF export for auditors\n",
    "\n",
    "### Perfect for:\n",
    "- üè¶ Financial Services (Credit, Insurance, Trading)\n",
    "- üè• Healthcare (Diagnosis, Treatment Planning)\n",
    "- ‚öñÔ∏è Legal Tech (Risk Assessment)\n",
    "- üèõÔ∏è Government (Public Services)\n",
    "- üè¢ Any Regulated Industry\n",
    "\n",
    "**XPLIA makes compliance easy, automatic, and trustworthy!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
